{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parker/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (5,23,24,29,83,265,282) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "def Init_CPS_Vars(CPS):\n",
    "\n",
    "    '''\n",
    "        Variables within the CPS that we use:\n",
    "\n",
    "    ssi_val     Supplemental Security income amount received\n",
    "    ssi_yn      Supplemental Security income received\n",
    "    ssikidyn    Supplemental Security income, child received\n",
    "    rednssi1    Supplemental Security income, reason 1\n",
    "    rednssi2    Supplemental Security income, reason 2\n",
    "    marsupwt    March supplement final weight\n",
    "    a_age       Age\n",
    "    a_spouse    Marital Status\n",
    "    fownu18     Non-married children under 18 in household\n",
    "    gestfips    FIPS State Code\n",
    "    pedisdrs    Disability, dressing or bathing\n",
    "    pedisear    Disability, hearing\n",
    "    pediseye    Disability, seeing\n",
    "    pedisout    Disability, doctor visits, shopping alone\n",
    "    pedisphy    Disability, walking, climbing stairs\n",
    "    pedisrem    Disability, remembering\n",
    "    dis_hp      Health problem or a disability which prevents working\n",
    "    rsnnotw     Reason for not working\n",
    "    vet_typ1    Veterans payments, type 1\n",
    "    pemlr       Monthly labor force recode\n",
    "    mcare       Medicare coverage\n",
    "    wsal_val    Total wage and salary earnings value\n",
    "    semp_val    Own business self-employment earnings, total value\n",
    "    frse_val    Farm self-employment earnings, total value\n",
    "    ss_val      Social Security payments received, value\n",
    "    rtm_val     Retirement income received, total amount\n",
    "    oi_off      Income sources, other\n",
    "    oi_val      Income, other (amount)\n",
    "    uc_yn       Unemployment compensation benefits received\n",
    "    uc_val      Unemployment compensation benefits value\n",
    "    int_yn      Interest received\n",
    "    int_val     Interest income received, amount+\n",
    "    ffpos       Record type and sequence indicator (similar numbers\n",
    "            indicate in same family)\n",
    "    fh_seq      Household sequence number (similar number indicate same Household)\n",
    "    finc_ssi    Supplemental Security benefits (Family)\n",
    "    ftot_r      Total family income\n",
    "    ftotval     Total family income\n",
    "    ptot_r      Person income, total\n",
    "    ptotval     Person income, total\n",
    "    peridnum    Unique Person identifier\n",
    "    '''\n",
    "    # These lists contain the column names that contain the missing data\n",
    "    Noneornot = ['ssi_val', 'csp_val', 'rnt_val', 'div_val', 'vet_val', 'wsal_val', 'semp_val', 'frse_val', 'ss_val', 'rtm_val', 'oi_val', 'uc_val', 'int_val', 'ftotval', 'ptotval', 'hwsval', 'pearnval', 'htotval']\n",
    "    NotInUniv = ['ssi_yn', 'dis_hp', 'rsnnotw', 'vet_typ1', 'uc_yn', 'int_yn', 'ptot_r', 'paw_yn', 'earner', 'hfdval']\n",
    "    NIU = ['ssikidyn', 'resnssi1', 'resnssi2', 'pedisdrs', 'pedisear', 'pediseye', 'pedisout', 'pedisphy', 'pedisrem', 'pemlr', 'oi_off']\n",
    "    # Add variables that indicate which entries of which columns contain missing values\n",
    "    for col in Noneornot:\n",
    "        CPS[col + '_missing_NoneIn'] = np.where(CPS[col] == 'None or not in universe', 1, 0)\n",
    "    for col in NotInUniv:\n",
    "        CPS[col + '_missing_NotIn'] = np.where(CPS[col] == 'Not in universe', 1, 0)\n",
    "    for col in NIU:\n",
    "        CPS[col + '_missing_NIU'] = np.where(CPS[col] == 'NIU', 1, 0)\n",
    "    \n",
    "    # Setting missing values equal to zero after adding binary variable\n",
    "    CPS = CPS.replace({'None or not in universe' : 0.}, regex = True)\n",
    "    CPS = CPS.replace({'Not in universe' : 0.}, regex = True)\n",
    "    CPS = CPS.replace({'NIU' : 0.}, regex = True)\n",
    "    CPS = CPS.replace({'Did not receive SSI' : 0.}, regex = True)\n",
    "    CPS = CPS.replace({'Received SSI' : 1.}, regex = True)\n",
    "    CPS = CPS.replace({'No' : 0.}, regex = True)\n",
    "    # Creating unearned income variable\n",
    "    CPS_unearned = (CPS[['fssval' ,'fretval' ,'foival' , 'fucval' , 'fintval', 'frntval', 'fdivval', 'fvetval', 'fcspval']].astype(float)).copy()\n",
    "    unearned_income = CPS_unearned.sum(axis = 1)\n",
    "    # Creating earned income variable\n",
    "    CPS_earned = (CPS[['fwsval' ,'fseval','ffrval']].astype(float)).copy()\n",
    "    earned_income = CPS_earned.sum(axis = 1)\n",
    "    # Determining current recipients of SSI benefit\n",
    "    CPS['current_recipient'] = np.where((CPS.ssi_yn =='Yes'), 1, 0)\n",
    "    CPS = CPS.replace({'Yes' : 1.}, regex = True)\n",
    "\n",
    "    CPS['fssival'] = (CPS['fssival'].astype(float)).copy()\n",
    "    CPS['earned_income'] = earned_income\n",
    "    CPS['unearned_income'] = unearned_income\n",
    "    # Below is a list of variables that are categorical but represented as strings\n",
    "    cols = ['a_ftpt', 'filestat', 'peridnum', 'ptot_r','ftot_r', 'pemlr', 'resnssi1', 'resnssi2', 'a_maritl', 'fownu18', 'oi_off', 'rsnnotw', 'pedisdrs', 'earner', 'prdtrace','hea', 'earner']\n",
    "    for col in cols:#Iterating through all of these categorical strings and converting to numbers below\n",
    "        CPS[col] = CPS[col].astype('category')\n",
    "\n",
    "    cat_columns = CPS.select_dtypes(['category']).columns\n",
    "    CPS[cat_columns] = CPS[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "    return CPS\n",
    "\n",
    "use_spm_data = True\n",
    "\n",
    "CPS = pd.read_csv('cpsmar2014t.csv')\n",
    "CPS = Init_CPS_Vars(CPS)\n",
    "\n",
    "CPS.a_age = np.where(CPS.a_age == \"80-84 years of age\",\n",
    "                     np.mean(np.arange(80,85)),\n",
    "                     CPS.a_age)\n",
    "CPS.a_age = np.where(CPS.a_age == \"85+ years of age\",\n",
    "                     np.mean(np.arange(85,96)),\n",
    "                     CPS.a_age)\n",
    "CPS.a_age = pd.to_numeric(CPS.a_age)\n",
    "CPS['80_84__missing'] = np.where(CPS['a_age'] == np.mean(np.arange(80,85)), 1, 0)\n",
    "CPS['85_95__missing'] = np.where(CPS['a_age'] == np.mean(np.arange(85,86)), 1, 0)\n",
    "\n",
    "key1 = CPS.columns.to_series().groupby(CPS.dtypes).groups.keys()[1]\n",
    "cols =  CPS.columns.to_series().groupby(CPS.dtypes).groups[key1].values\n",
    "for col in cols:\n",
    "    CPS[col] = CPS[col].astype('category')\n",
    "CPS[cols] = CPS[cols].apply(lambda x: x.cat.codes)\n",
    "CPS = CPS.fillna(0) \n",
    "\n",
    "CPS_unearned = (CPS[['fssval' ,'fretval' ,'foival' , 'fucval' , 'fintval', 'frntval', 'fdivval', 'fvetval', 'fcspval']].astype(float)).copy()\n",
    "unearned_income = CPS_unearned.sum(axis = 1)\n",
    "# Creating earned income variable\n",
    "CPS_earned = (CPS[['fwsval' ,'fseval','ffrval']].astype(float)).copy()\n",
    "earned_income = CPS_earned.sum(axis = 1)\n",
    "# Determining current recipients of SSI benefit\n",
    "\n",
    "CPS['fam_earned_income'] = earned_income\n",
    "CPS['fam_unearned_income'] = unearned_income\n",
    "CPS.to_pickle('CPS_family.pickle')\n",
    "\n",
    "\n",
    "# CPS_dataset = pd.read_pickle('CPS_family.pickle')\n",
    "CPS_dataset = CPS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_spm_data == True:\n",
    "    # Get data from https://www.census.gov/data/datasets/2013/demo/supplemental-poverty-measure/spm.html SPM data from 2013 since 2014 cps reflects what happened in 2013\n",
    "    spm_data = pd.read_stata('spmresearch2013new.dta')\n",
    "    CPS_dataset = CPS_dataset.merge(spm_data[['spmu_caphousesub', 'h_seq', 'pppos']], on = ['h_seq', 'pppos'])\n",
    "    CPS_dataset['fhoussub'] = CPS_dataset['spmu_caphousesub']\n",
    "    CPS_dataset = CPS_dataset.drop('spmu_caphousesub', 1)\n",
    "\n",
    "\n",
    "#Removing those who receive hlorent, but who have no subsequent fhoussub value to describe it\n",
    "CPS_dataset.hlorent = np.where((CPS_dataset.hlorent == 1) & (CPS_dataset.fhoussub == 0),\n",
    "     0, CPS_dataset.hlorent)\n",
    "CPS_dataset.hpublic = np.where((CPS_dataset.hpublic == 1) & (CPS_dataset.fhoussub == 0),\n",
    "     0, CPS_dataset.hpublic)\n",
    "CPS_dataset['housing'] = np.where((CPS_dataset.hpublic == 1) | (CPS_dataset.hlorent == 1),\n",
    "     1, 0)\n",
    "CPS_dataset = CPS_dataset.drop(['hpublic', 'hlorent'],1)\n",
    "\n",
    "#Earned income\n",
    "p_earned = CPS_dataset.wsal_val + CPS_dataset.semp_val + CPS_dataset.frse_val #individual earned income\n",
    "CPS_dataset['p_earned'] = p_earned\n",
    "\n",
    "\n",
    "#Unearned income\n",
    "p_unearned = CPS_dataset.ss_val + CPS_dataset.rtm_val + CPS_dataset.div_val + \\\n",
    "    CPS_dataset.oi_off + CPS_dataset.uc_yn + CPS_dataset.int_yn\n",
    "CPS_dataset['p_unearned'] = p_unearned\n",
    "\n",
    "#Net Income\n",
    "CPS_dataset['family_net_income'] = p_earned + p_unearned\n",
    "\n",
    "#disabled (check reg if categorical or binary is better after the sum)\n",
    "CPS_dataset['disability'] = np.zeros(len(CPS_dataset))\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisdrs == 1, 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisear == 1, 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pediseye == 1, 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisout == 1, 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisphy == 1, 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisrem == 1, 1, CPS_dataset.disability)\n",
    "\n",
    "\n",
    "\n",
    "# #State residency of family and weights\n",
    "\n",
    "CPS_dataset_mean = CPS_dataset.groupby(['fh_seq', 'ffpos']).mean()\n",
    "CPS_dataset_sum = CPS_dataset.groupby(['fh_seq', 'ffpos']).sum()\n",
    "CPS_dataset2 = pd.merge(CPS_dataset_mean, CPS_dataset_sum, left_index = True, right_index = True, how = 'inner',\\\n",
    "                       suffixes = ('_mean', '_sum'))\n",
    "\n",
    "CPS = CPS_dataset2\n",
    "# CPS_dataset2.to_pickle('use_df_hlo_rf.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CPS = pd.read_pickle('use_df_hlo_rf.pickle')\n",
    "Rf = rf(n_estimators = 200, min_samples_leaf = 6, max_depth = 10) # Creating Random Forest \n",
    "CPS_use = CPS.drop('peridnum_mean', 1)\n",
    "CPS_use = CPS.drop('peridnum_sum', 1)\n",
    "\n",
    "#Splitting data into training and test sets\n",
    "train = CPS_use.sample(frac=0.8, random_state=1)\n",
    "train_x = train.copy()\n",
    "train_x = train_x.drop(['hunits_sum', 'hhpos_sum', 'h_seq_sum', 'hrecord_sum', 'ph_seq_sum',\\\n",
    "                        'housing_sum','fhoussub_sum', 'hssival_sum', 'hunits_mean', 'hhpos_mean',\\\n",
    "                        'h_seq_mean', 'hrecord_mean', 'ph_seq_mean','housing_mean','fhoussub_mean',\\\n",
    "                        'hssival_mean', 'hsup_wgt_mean', 'fsup_wgt_mean', 'marsupwt_mean',\\\n",
    "                        'hsup_wgt_sum', 'marsupwt_sum', 'fsup_wgt_sum','htotval_mean', 'peridnum_mean',\\\n",
    "                        'h_idnum1_sum', 'h_idnum1_mean','htotval_sum','hfdval_sum'],1)\n",
    "\n",
    "\n",
    "\n",
    "test_x = CPS_use.loc[~CPS_use.index.isin(train_x.index)]\n",
    "test_y = test_x['housing_mean']\n",
    "test_x = test_x.drop(['hunits_sum', 'hhpos_sum', 'h_seq_sum', 'hrecord_sum', 'ph_seq_sum',\\\n",
    "                        'housing_sum','fhoussub_sum', 'hssival_sum', 'hunits_mean', 'hhpos_mean',\\\n",
    "                        'h_seq_mean', 'hrecord_mean', 'ph_seq_mean','housing_mean','fhoussub_mean',\\\n",
    "                        'hssival_mean', 'hsup_wgt_mean', 'fsup_wgt_mean', 'marsupwt_mean',\\\n",
    "                        'hsup_wgt_sum', 'marsupwt_sum', 'fsup_wgt_sum','htotval_mean', 'peridnum_mean',\\\n",
    "                        'h_idnum1_sum', 'h_idnum1_mean','htotval_sum','hfdval_sum'],1)\n",
    "\n",
    "\n",
    "# Fitting the Random Forest model to the training set\n",
    "Rf.fit(train_x, train['housing_mean'])\n",
    "print Rf.feature_importances_, train_x.columns.values\n",
    "predictions = Rf.predict(test_x)\n",
    "print 'score:', Rf.score(test_x, test_y) # Printing Random Forest accuracy\n",
    "fimp = Rf.feature_importances_\n",
    "colvals = train_x.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = Rf.feature_importances_\n",
    "maxes = np.argsort(features)[::-1]\n",
    "print maxes\n",
    "print list(train_x[maxes].columns.values)\n",
    "print features[maxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_probs = CPS_use.copy()\n",
    "get_probs = get_probs.drop(['hunits_sum', 'hhpos_sum', 'h_seq_sum', 'hrecord_sum', 'ph_seq_sum',\\\n",
    "                        'housing_sum','fhoussub_sum', 'hssival_sum', 'hunits_mean', 'hhpos_mean',\\\n",
    "                        'h_seq_mean', 'hrecord_mean', 'ph_seq_mean','housing_mean','fhoussub_mean',\\\n",
    "                        'hssival_mean', 'hsup_wgt_mean', 'fsup_wgt_mean', 'marsupwt_mean',\\\n",
    "                        'hsup_wgt_sum', 'marsupwt_sum', 'fsup_wgt_sum','htotval_mean', 'peridnum_mean',\\\n",
    "                        'h_idnum1_sum', 'h_idnum1_mean','htotval_sum','hfdval_sum'],1)\n",
    "\n",
    "prediction_vec = Rf.predict_proba(get_probs)\n",
    "print prediction_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_spm_data == True:\n",
    "    np.savetxt('rf_probs_spm.csv', prediction_vec)\n",
    "    \n",
    "else:\n",
    "    np.savetxt('rf_probs.csv', prediction_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
