{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This script imputes Supplemental Nutrition Assistance Program (SNAP) recipients dollar benefit amount to match the aggregates with United States Department of Agriculture (USDA) statistics for SNAP. In this current version, we used 2014 CPS data and USDA FY2014 annual reports on SNAP. Please refer to the documentation in the same folder for more details on methodology and assumptions. The output this script is a personal level dataset that contains CPS household level sequence (h_seq), individual participation indicator (snap_participation, 0 - not a recipient, 1 - current recipient on file, 2 - imputed recipient), and benefit amount.\n",
    "\n",
    "Input: 2014 CPS (cpsmar2014t.csv), number of recipients and their benefits amount by state in 2014 (Administrative.csv)\n",
    "\n",
    "Output: SNAP_Imputation.csv\n",
    "\n",
    "Additional Source links: http://www.fns.usda.gov/pd/supplemental-nutrition-assistance-program-snap (zipfile for FY69 through FY16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Amy/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (5,23,24,29,83,265,282) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "CPS_dataset = pd.read_csv('/PATH_TO_RAW_CPS/cpsmar2014t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andersonfrailey/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (5,23,24,29,83,265,282) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Variables we use in CPS:\n",
    "columns_to_keep = ['hfoodsp','hfdval','h_numper','h_seq','a_age','marsupwt','moop','hhi_yn','chsp_val',\n",
    "                   'gestfips','pedisout','pedisdrs','pedisear', 'pedisrem','pediseye', 'pedisphy', \n",
    "                   'vet_typ1','vet_yn','pemlr','filestat','wsal_val','semp_val','frse_val',\n",
    "                   'ss_val','rtm_val','oi_val','oi_off','int_yn','uc_yn', 'wc_yn','ss_yn', 'paw_yn',\n",
    "                   'uc_val','int_val','hfoodmo', 'sur_yn', 'hcsp_yn', 'hed_yn', 'mcaid', 'mcare',\n",
    "                   'fsup_wgt', 'hsup_wgt','h_respnm', 'ssi_yn','a_exprrp', 'perrp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CPS_dataset = CPS_dataset[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recipient or not\n",
    "CPS_dataset.hfoodsp = np.where(CPS_dataset.hfoodsp == \"Yes\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare household level data\n",
    "household_SNAP = CPS_dataset.groupby('h_seq')['hfoodsp'].mean()\n",
    "household_size = CPS_dataset.groupby('h_seq')['h_numper'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Earned income\n",
    "wage = pd.to_numeric(np.where(CPS_dataset.wsal_val!= 'None or not in universe', CPS_dataset.wsal_val, 0))\n",
    "self_employed1 = pd.to_numeric(np.where(CPS_dataset.semp_val!= 'None or not in universe', CPS_dataset.semp_val, 0))\n",
    "self_employed2 = pd.to_numeric(np.where(CPS_dataset.frse_val!= 'None or not in universe', CPS_dataset.frse_val, 0))\n",
    "p_earned = wage + self_employed1 + self_employed2 #individual earned income\n",
    "p_earned = 0.8 * p_earned #for net income calculation, there is a 20% deduction in earned income\n",
    "CPS_dataset['p_earned'] = p_earned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Unearned income\n",
    "ss = pd.to_numeric(np.where(CPS_dataset.ss_val!='None or not in universe', CPS_dataset.ss_val, 0))\n",
    "pension = pd.to_numeric(np.where(CPS_dataset.rtm_val!='None or not in universe', CPS_dataset.rtm_val, 0))\n",
    "disability = pd.to_numeric(np.where(CPS_dataset.oi_off=='State disability payments', CPS_dataset.oi_val, 0))\n",
    "unemploy = pd.to_numeric(np.where(CPS_dataset.uc_yn=='Yes', CPS_dataset.uc_val, 0))\n",
    "interest = pd.to_numeric(np.where(CPS_dataset.int_yn=='Yes', CPS_dataset.int_val, 0))\n",
    "p_unearned = ss + pension + disability + unemploy + interest #individual unearned income\n",
    "CPS_dataset['p_unearned'] = p_unearned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Net Income\n",
    "CPS_dataset['hh_net_income'] = p_earned + p_unearned\n",
    "hh_net_income = CPS_dataset.groupby('h_seq')['hh_net_income'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_SNAP = DataFrame(household_SNAP.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP['hh_net'] = hh_net_income\n",
    "hh_SNAP['hh_size'] = household_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_SNAP.columns = ['indicator', 'hh_net','hh_size'] #indicator is hfoodsp, a dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#net income deduction\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size <=3, hh_SNAP.hh_net-155*12, hh_SNAP.hh_net)\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size ==4, hh_SNAP.hh_net-168*12, hh_SNAP.hh_net)\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size ==5, hh_SNAP.hh_net-197*12, hh_SNAP.hh_net)\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_size >=6, hh_SNAP.hh_net-226*12, hh_SNAP.hh_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#medical deduction\n",
    "#age over 60\n",
    "CPS_dataset.a_age = np.where(CPS_dataset.a_age == \"80-84 years of age\",\n",
    "                             random.randrange(80, 84),\n",
    "                             CPS_dataset.a_age)\n",
    "CPS_dataset.a_age = np.where(CPS_dataset.a_age == \"85+ years of age\",\n",
    "                             random.randrange(85, 95),\n",
    "                             CPS_dataset.a_age)\n",
    "CPS_dataset.a_age = pd.to_numeric(CPS_dataset.a_age)\n",
    "#disabled\n",
    "CPS_dataset['disability'] = np.zeros(len(CPS_dataset))\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisdrs == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisear == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pediseye == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisout == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisphy == 'Yes', 1, CPS_dataset.disability)\n",
    "CPS_dataset.disability = np.where(CPS_dataset.pedisrem == 'Yes', 1, CPS_dataset.disability)\n",
    "#deduction of more than $35 for a month\n",
    "CPS_dataset.hhi_yn = np.where(CPS_dataset.hhi_yn == 'Yes', 1, 0)\n",
    "CPS_dataset.moop = np.where(CPS_dataset.moop != 'NIU', CPS_dataset.moop, 0)\n",
    "CPS_dataset['medical'] = np.zeros(len(CPS_dataset))\n",
    "CPS_dataset.medical = np.where((CPS_dataset.hhi_yn == 0), CPS_dataset.moop, 0)\n",
    "CPS_dataset.medical = np.where((CPS_dataset.disability == 1.0)|(CPS_dataset.a_age >= 60), CPS_dataset.moop, 0)\n",
    "CPS_dataset.medical = pd.to_numeric(CPS_dataset.medical)\n",
    "hh_medical = CPS_dataset.groupby('h_seq')['medical'].sum()\n",
    "hh_SNAP['hh_medical'] = hh_medical\n",
    "hh_SNAP.hh_net = np.where(hh_medical > 35*12, hh_SNAP.hh_net-(hh_medical-35*12), hh_SNAP.hh_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP['disability'] = CPS_dataset.groupby('h_seq')['disability'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#child support\n",
    "CPS_dataset.chsp_val = np.where(CPS_dataset.chsp_val == \"NIU\", 0, CPS_dataset.chsp_val)\n",
    "CPS_dataset.chsp_val = pd.to_numeric(CPS_dataset.chsp_val)\n",
    "hh_child = CPS_dataset.groupby('h_seq')['chsp_val'].sum()\n",
    "hh_SNAP['hh_child'] = hh_child\n",
    "hh_SNAP.hh_net = hh_SNAP.hh_net - hh_SNAP.hh_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset['children_yn'] = np.where(CPS_dataset.a_age<=18,1,0)\n",
    "hh_SNAP['child_yn'] = CPS_dataset.groupby('h_seq')['children_yn'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.hh_net = hh_SNAP.hh_net - (10+290)*12 #dependent care; excess shelter. All based on SNAP official average\n",
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_net <0, 0, hh_SNAP.hh_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keep a reasonable subset\n",
    "hh_SNAP.hh_net = np.where((hh_SNAP.hh_net > 5490 * 12) & (hh_SNAP.indicator==0), -100, hh_SNAP.hh_net)\n",
    "hh_SNAP = hh_SNAP[hh_SNAP.hh_net>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.to_csv('check3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP['intercept'] = np.ones(len(hh_SNAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other welfare program participation indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CPS_dataset.ssi_yn = np.where(CPS_dataset.ssi_yn=='Yes', 1, 0)\n",
    "hh_SNAP['ssi_yn'] = CPS_dataset.groupby('h_seq')['ssi_yn'].sum()\n",
    "hh_SNAP['ssi_yn'] = np.where(hh_SNAP.ssi_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CPS_dataset.ss_yn = np.where(CPS_dataset.ss_yn=='Yes', 1, 0)\n",
    "hh_SNAP['ss_yn'] = CPS_dataset.groupby('h_seq')['ss_yn'].sum()\n",
    "hh_SNAP['ss_yn'] = np.where(hh_SNAP.ss_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.wc_yn = np.where(CPS_dataset.wc_yn=='Yes', 1, 0)\n",
    "hh_SNAP['wc_yn'] = CPS_dataset.groupby('h_seq')['wc_yn'].sum()\n",
    "hh_SNAP['wc_yn'] = np.where(hh_SNAP.wc_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CPS_dataset.uc_yn = np.where(CPS_dataset.uc_yn=='Yes', 1, 0)\n",
    "hh_SNAP['uc_yn'] = CPS_dataset.groupby('h_seq')['uc_yn'].sum()\n",
    "hh_SNAP['uc_yn'] = np.where(hh_SNAP.uc_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.paw_yn = np.where(CPS_dataset.paw_yn=='Yes', 1, 0)\n",
    "hh_SNAP['paw_yn'] = CPS_dataset.groupby('h_seq')['paw_yn'].sum()\n",
    "hh_SNAP['paw_yn'] = np.where(hh_SNAP.paw_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.vet_yn = np.where(CPS_dataset.vet_yn=='Yes', 1, 0)\n",
    "hh_SNAP['vet_yn'] = CPS_dataset.groupby('h_seq')['vet_yn'].sum()\n",
    "hh_SNAP['vet_yn'] = np.where(hh_SNAP.vet_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.sur_yn = np.where(CPS_dataset.sur_yn=='Yes', 1, 0)\n",
    "hh_SNAP['sur_yn'] = CPS_dataset.groupby('h_seq')['sur_yn'].sum()\n",
    "hh_SNAP['sur_yn'] = np.where(hh_SNAP.sur_yn>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.mcare = np.where(CPS_dataset.mcare=='Yes', 1, 0)\n",
    "hh_SNAP['mcare'] = CPS_dataset.groupby('h_seq')['mcare'].sum()\n",
    "hh_SNAP['mcare'] = np.where(hh_SNAP.mcare>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset.mcaid = np.where(CPS_dataset.mcaid=='Yes', 1, 0)\n",
    "hh_SNAP['mcaid'] = CPS_dataset.groupby('h_seq')['mcaid'].sum()\n",
    "hh_SNAP['mcaid'] = np.where(hh_SNAP.mcaid>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CPS_dataset['ABAWD'] = np.where((CPS_dataset.a_age>18)&(CPS_dataset.a_age<49)&(CPS_dataset.disability==0), 1, 0)\n",
    "CPS_dataset['ABAWD'] = np.where((CPS_dataset.a_exprrp=='Reference person without')|(CPS_dataset.a_exprrp=='Partner/roommate'), \n",
    "                                CPS_dataset.ABAWD, 0)\n",
    "hh_SNAP['ABAWD'] = CPS_dataset.groupby('h_seq')['ABAWD'].mean()\n",
    "hh_SNAP['ABAWD'] = np.where(hh_SNAP.ABAWD!=0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_SNAP.hh_net = np.where(hh_SNAP.hh_net > 5490 * 12, -100, hh_SNAP.hh_net)\n",
    "hh_SNAP = hh_SNAP[hh_SNAP.hh_net>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.285025\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              indicator   No. Observations:                37780\n",
      "Model:                          Logit   Df Residuals:                    37765\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Mon, 15 May 2017   Pseudo R-squ.:                  0.3597\n",
      "Time:                        18:51:18   Log-Likelihood:                -10768.\n",
      "converged:                       True   LL-Null:                       -16817.\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "hh_net     -7.362e-05   1.52e-06    -48.444      0.000     -7.66e-05 -7.06e-05\n",
      "hh_size        0.1457      0.024      6.069      0.000         0.099     0.193\n",
      "disability     0.3142      0.034      9.141      0.000         0.247     0.382\n",
      "child_yn       0.2667      0.030      8.777      0.000         0.207     0.326\n",
      "ABAWD          0.2421      0.054      4.457      0.000         0.136     0.349\n",
      "ssi_yn         0.2928      0.060      4.875      0.000         0.175     0.411\n",
      "intercept     -2.0794      0.050    -41.370      0.000        -2.178    -1.981\n",
      "uc_yn          0.8390      0.068     12.270      0.000         0.705     0.973\n",
      "paw_yn         1.3801      0.102     13.536      0.000         1.180     1.580\n",
      "vet_yn        -0.6743      0.130     -5.183      0.000        -0.929    -0.419\n",
      "sur_yn        -0.7888      0.142     -5.567      0.000        -1.067    -0.511\n",
      "mcare         -0.1265      0.061     -2.068      0.039        -0.246    -0.007\n",
      "mcaid          1.7742      0.042     42.515      0.000         1.692     1.856\n",
      "ss_yn          0.5076      0.061      8.347      0.000         0.388     0.627\n",
      "wc_yn         -0.0916      0.169     -0.544      0.587        -0.422     0.239\n",
      "==============================================================================\n"

     ]
    }
   ],
   "source": [
    "#Regression\n",
    "model = sm.Logit(endog= hh_SNAP.indicator, exog= hh_SNAP[['hh_net', 'hh_size','disability','child_yn','ABAWD',\n",
    "                                                          'ssi_yn','intercept', 'uc_yn', 'paw_yn', 'vet_yn',\n",
    "                                                          'sur_yn', 'mcare', 'mcaid', 'ss_yn', 'wc_yn']]).fit()\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keep household with 1 member\n",
    "hh_SNAP['probs'] = model.predict()\n",
    "probs = hh_SNAP.probs[hh_SNAP.hh_size==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11349"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hh_SNAP[hh_SNAP.hh_size==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11349 37780\n"
     ]
    }
   ],
   "source": [
    "print len(probs), len(hh_SNAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare household's weights; states; SNAP value\n",
    "household_marsupwt = CPS_dataset.groupby('h_seq')['hsup_wgt'].mean()\n",
    "hh_SNAP['hh_marsupwt'] = household_marsupwt\n",
    "\n",
    "household_gestfips = CPS_dataset.groupby('h_seq')['gestfips'].mean()\n",
    "hh_SNAP['hh_gestfips'] = household_gestfips\n",
    "\n",
    "CPS_dataset.hfdval = np.where(CPS_dataset.hfdval!= 'Not in universe', CPS_dataset.hfdval, 0)\n",
    "CPS_dataset.hfdval = pd.to_numeric(CPS_dataset.hfdval)\n",
    "household_hfdval = CPS_dataset.groupby('h_seq')['hfdval'].mean()\n",
    "hh_SNAP['hh_hfdval'] = household_hfdval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare household's length of being recipients\n",
    "CPS_dataset.hfoodmo = np.where(CPS_dataset.hfoodmo == 'Not in universe', 0, CPS_dataset.hfoodmo)\n",
    "CPS_dataset.hfoodmo = np.where(CPS_dataset.hfoodmo == '12 Months', 12, CPS_dataset.hfoodmo)\n",
    "CPS_dataset.hfoodmo = np.where(CPS_dataset.hfoodmo == '1 month', 1, CPS_dataset.hfoodmo)\n",
    "CPS_dataset.hfoodmo = pd.to_numeric(CPS_dataset.hfoodmo)\n",
    "household_hfoodmo = CPS_dataset.groupby('h_seq')['hfoodmo'].mean()\n",
    "hh_SNAP['hh_hfoodmo'] = household_hfoodmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import administrative level data\n",
    "admin = pd.read_csv('SNAP_Administrative.csv',\n",
    "                    dtype={ 'Household number': np.float,'Average household benefit': np.float, \n",
    "                            'Total': np.float, 'Individual number': np.float})\n",
    "admin.index = admin.Fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CPS total benefits and Administrative total benefits\n",
    "state_benefit = {}\n",
    "state_recipients = {}\n",
    "for state in admin.Fips:\n",
    "    this_state = (hh_SNAP.hh_gestfips==state)\n",
    "    CPS_totalb = (hh_SNAP.hh_hfdval * hh_SNAP.hh_marsupwt / hh_SNAP.hh_hfoodmo)[this_state].sum()/1000000 #in million, per month\n",
    "    admin_totalb =  admin.Total[state] /12 /1000000 # in million, per month\n",
    "    CPS_totaln = (hh_SNAP.hh_marsupwt[this_state&hh_SNAP.indicator==1]*hh_SNAP.hh_hfoodmo/12).sum()/1000 # in thousand, per month\n",
    "    admin_totaln =  admin[\"Household number\"][state] /1000 #household in thousand, per month\n",
    "    CPS_totalnindividual = (hh_SNAP.hh_marsupwt* hh_SNAP.hh_size[this_state&hh_SNAP.indicator==1]*hh_SNAP.hh_hfoodmo/12).sum()/1000 # in thousand, per month\n",
    "    admin_totalnindividual =  admin[\"Individual number\"][state] /1000 #individual in thousand, per month\n",
    "    \n",
    "    temp = [admin.State[state], CPS_totalb, admin_totalb, CPS_totaln, admin_totaln, CPS_totalnindividual, admin_totalnindividual]\n",
    "    state_benefit[state] = temp\n",
    "    \n",
    "pre_augment_benefit = DataFrame(state_benefit).transpose()\n",
    "pre_augment_benefit.columns = ['State', 'CPS total benefits(monthly)','Admin total benefits(monthly)',\n",
    "                               'CPS total household recipient(monthly)','Admin total household recipient(monthly)',\n",
    "                               'CPS total individual recipient(monthly)','Admin total individual recipient(monthly)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_augment_benefit.to_csv('pre-blow-up.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# caculate difference of SNAP stats and CPS aggregates on recipients number\n",
    "# by state\n",
    "diff = {'Fips':[],'Difference in Population':[],'Mean Benefit':[],'CPS Population':[],'SNAP Population':[]}\n",
    "diff['Fips'] = admin.Fips\n",
    "current = (hh_SNAP.indicator==1)\n",
    "for FIPS in admin.Fips:\n",
    "        this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "        current_tots = (hh_SNAP.hh_marsupwt[current&this_state]*hh_SNAP.hh_hfoodmo/12).sum()\n",
    "        valid_num = (hh_SNAP.hh_marsupwt[current&this_state]*hh_SNAP.hh_hfoodmo/12).sum() + 0.0000001\n",
    "        current_mean = ((hh_SNAP.hh_hfdval * hh_SNAP.hh_marsupwt / hh_SNAP.hh_hfoodmo)[current&this_state].sum())/valid_num\n",
    "        diff['CPS Population'].append(current_tots)\n",
    "        diff['SNAP Population'].append(float(admin[\"Household number\"][admin.Fips == FIPS]))\n",
    "        diff['Difference in Population'].append(float(admin[\"Household number\"][admin.Fips == FIPS])- current_tots)\n",
    "        diff['Mean Benefit'].append(current_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = DataFrame(diff)\n",
    "d = d[['Fips', 'Mean Benefit', 'Difference in Population', 'CPS Population', 'SNAP Population']]\n",
    "d.to_csv('recipients.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Amy/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/Users/Amy/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:23: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/Users/Amy/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Amy/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('we need to impute', 199827.875, 'for state', 1)\n",
      "('Method1: regression gives', 198441.24999999994)\n",
      "('we need to impute', 17340.358333333334, 'for state', 2)\n",
      "('Method1: regression gives', 17027.29)\n",
      "('we need to impute', 139886.15249999997, 'for state', 4)\n",
      "('Method1: regression gives', 139915.18)\n",
      "('we need to impute', 65664.035000000033, 'for state', 5)\n",
      "('Method1: regression gives', 64860.509999999995)\n",
      "('we need to impute', 1090897.3050000002, 'for state', 6)\n",
      "('Method1: regression gives', 1090030.2100000002)\n",
      "('we need to impute', 93199.099166666711, 'for state', 8)\n",
      "('Method1: regression gives', 93969.49)\n",
      "('we need to impute', 114740.1358333333, 'for state', 9)\n",
      "('Method1: regression gives', 114392.99)\n",
      "('we need to impute', 32674.193333333322, 'for state', 10)\n",
      "('Method1: regression gives', 32816.93)\n",
      "('we need to impute', 43272.205833333333, 'for state', 11)\n",
      "('Method1: regression gives', 43242.84)\n",
      "('we need to impute', 1140532.6958333338, 'for state', 12)\n",
      "('Method1: regression gives', 1142961.4799999988)\n",
      "('we need to impute', 484924.43499999982, 'for state', 13)\n",
      "('Method1: regression gives', 483126.91)\n",
      "('we need to impute', 55883.185833333344, 'for state', 15)\n",
      "('Method1: regression gives', 55711.46999999998)\n",
      "('we need to impute', 42032.035833333328, 'for state', 16)\n",
      "('Method1: regression gives', 42350.21)\n",
      "('we need to impute', 601288.48750000016, 'for state', 17)\n",
      "('Method1: regression gives', 601716.7699999999)\n",
      "('we need to impute', 182141.04250000001, 'for state', 18)\n",
      "('Method1: regression gives', 181273.80999999997)\n",
      "('we need to impute', 78323.353333333303, 'for state', 19)\n",
      "('Method1: regression gives', 77706.28000000004)\n",
      "('we need to impute', 48234.197500000068, 'for state', 20)\n",
      "('Method1: regression gives', 47870.96000000001)\n",
      "('we need to impute', 163247.60833333337, 'for state', 21)\n",
      "('Method1: regression gives', 161511.13)\n",
      "('we need to impute', 209608.98499999999, 'for state', 22)\n",
      "('Method1: regression gives', 211945.13)\n",
      "('we need to impute', 37894.015833333382, 'for state', 23)\n",
      "('Method1: regression gives', 38167.869999999995)\n",
      "('we need to impute', 215878.52166666675, 'for state', 24)\n",
      "('Method1: regression gives', 216447.39000000004)\n",
      "('we need to impute', 203132.5833333332, 'for state', 25)\n",
      "('Method1: regression gives', 202045.03)\n",
      "('we need to impute', 346327.18083333364, 'for state', 26)\n",
      "('Method1: regression gives', 347756.4000000001)\n",
      "('we need to impute', 93632.677500000078, 'for state', 27)\n",
      "('Method1: regression gives', 93226.03)\n",
      "('we need to impute', 89393.706666666752, 'for state', 28)\n",
      "('Method1: regression gives', 88746.68000000002)\n",
      "('we need to impute', 124457.18833333341, 'for state', 29)\n",
      "('Method1: regression gives', 124769.26999999999)\n",
      "('we need to impute', 23969.917499999996, 'for state', 30)\n",
      "('Method1: regression gives', 24773.57)\n",
      "('we need to impute', 31423.005000000019, 'for state', 31)\n",
      "('Method1: regression gives', 31185.91)\n",
      "('we need to impute', 83237.873333333351, 'for state', 32)\n",
      "('Method1: regression gives', 83108.37)\n",
      "('we need to impute', 21399.049166666657, 'for state', 33)\n",
      "('Method1: regression gives', 21668.520000000004)\n",
      "('we need to impute', 223754.54583333325, 'for state', 34)\n",
      "('Method1: regression gives', 226780.00000000003)\n",
      "('we need to impute', 117057.51666666666, 'for state', 35)\n",
      "('Method1: regression gives', 115823.81000000006)\n",
      "('we need to impute', 745430.78333333251, 'for state', 36)\n",
      "('Method1: regression gives', 744484.21)\n",
      "('we need to impute', 332595.98000000016, 'for state', 37)\n",
      "('Method1: regression gives', 333526.07999999996)\n",
      "('we need to impute', -1027.2124999999942, 'for state', 38)\n",
      "('we need to impute', 228323.36083333322, 'for state', 39)\n",
      "('Method1: regression gives', 227342.81)\n",
      "('we need to impute', 154952.41833333333, 'for state', 40)\n",
      "('Method1: regression gives', 155067.82000000004)\n",
      "('we need to impute', 237683.81999999992, 'for state', 41)\n",
      "('Method1: regression gives', 238633.49999999997)\n",
      "('we need to impute', 411244.5033333333, 'for state', 42)\n",
      "('Method1: regression gives', 409947.88000000006)\n",
      "('we need to impute', 34864.514999999999, 'for state', 44)\n",
      "('Method1: regression gives', 35195.16)\n",
      "('we need to impute', 151613.80999999997, 'for state', 45)\n",
      "('Method1: regression gives', 150974.95000000007)\n",
      "('we need to impute', 18159.834999999995, 'for state', 46)\n",
      "('Method1: regression gives', 18269.01)\n",
      "('we need to impute', 247536.29916666658, 'for state', 47)\n",
      "('Method1: regression gives', 249641.68)\n",
      "('we need to impute', 650695.21416666673, 'for state', 48)\n",
      "('Method1: regression gives', 651140.9699999995)\n",
      "('we need to impute', 27094.94249999999, 'for state', 49)\n",
      "('Method1: regression gives', 26382.579999999998)\n",
      "('we need to impute', 23358.709166666667, 'for state', 50)\n",
      "('Method1: regression gives', 23214.629999999994)\n",
      "('we need to impute', 244489.18083333338, 'for state', 51)\n",
      "('Method1: regression gives', 245506.30999999997)\n",
      "('we need to impute', 344530.8666666667, 'for state', 53)\n",
      "('Method1: regression gives', 342652.04999999993)\n",
      "('we need to impute', 81690.806666666642, 'for state', 54)\n",
      "('Method1: regression gives', 82434.30999999998)\n",
      "('we need to impute', 199642.98750000008, 'for state', 55)\n",
      "('Method1: regression gives', 200972.87000000002)\n",
      "('we need to impute', 2079.611666666664, 'for state', 56)\n",
      "('Method1: regression gives', 1875.28)\n"
     ]
    }
   ],
   "source": [
    "hh_SNAP['impute'] = np.zeros(len(hh_SNAP))\n",
    "hh_SNAP['snap_impute'] = np.zeros(len(hh_SNAP))\n",
    "\n",
    "non_current = (hh_SNAP.indicator==0)\n",
    "current = (hh_SNAP.indicator==1)\n",
    "random.seed()\n",
    "\n",
    "for FIPS in admin.Fips:\n",
    "    \n",
    "        print ('we need to impute', d['Difference in Population'][FIPS], 'for state', FIPS)\n",
    "        \n",
    "        if d['Difference in Population'][FIPS] < 0:\n",
    "            continue\n",
    "        else:\n",
    "            this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "            not_imputed = (hh_SNAP.impute==0)\n",
    "            pool_index = hh_SNAP[this_state&not_imputed&non_current].index\n",
    "            pool = DataFrame({'weight': hh_SNAP.hh_marsupwt[pool_index], 'prob': probs[pool_index]},\n",
    "                            index=pool_index)\n",
    "            pool = pool.sort_values(by='prob', ascending=False)\n",
    "            pool['cumsum_weight'] = pool['weight'].cumsum()\n",
    "            pool['distance'] = abs(pool.cumsum_weight-d['Difference in Population'][FIPS])\n",
    "            min_index = pool.sort_values(by='distance')[:1].index\n",
    "            min_weight = int(pool.loc[min_index].cumsum_weight)\n",
    "            pool['impute'] = np.where(pool.cumsum_weight<=min_weight+10 , 1, 0)\n",
    "            hh_SNAP.impute[pool.index[pool['impute']==1]] = 1\n",
    "            hh_SNAP.snap_impute[pool.index[pool['impute']==1]] = admin['Average household benefit'][FIPS]*12\n",
    "\n",
    "        print ('Method1: regression gives', \n",
    "                hh_SNAP.hh_marsupwt[(hh_SNAP.impute==1)&this_state].sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adjustment ratio\n",
    "results = {}\n",
    "\n",
    "imputed = (hh_SNAP.impute == 1)\n",
    "has_val = (hh_SNAP.hh_hfdval != 0)\n",
    "no_val = (hh_SNAP.hh_hfdval == 0)\n",
    "\n",
    "for FIPS in admin.Fips:\n",
    "    this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "    \n",
    "    current_total = (hh_SNAP.hh_hfdval * hh_SNAP.hh_marsupwt)[this_state].sum() #yearly benefit\n",
    "    imputed_total = (hh_SNAP.snap_impute * hh_SNAP.hh_marsupwt)[this_state&imputed].sum()\n",
    "    on_file = current_total + imputed_total\n",
    "\n",
    "    admin_total = admin.Total[FIPS]\n",
    "    \n",
    "    adjust_ratio = admin_total / on_file\n",
    "    this_state_num = [admin['State'][FIPS], on_file, admin_total, adjust_ratio]\n",
    "    results[FIPS] = this_state_num\n",
    "    \n",
    "\n",
    "    hh_SNAP.snap_impute = np.where(has_val&this_state, hh_SNAP.hh_hfdval * adjust_ratio, hh_SNAP.snap_impute)\n",
    "    hh_SNAP.snap_impute = np.where(no_val&this_state, hh_SNAP.snap_impute * adjust_ratio, hh_SNAP.snap_impute)\n",
    "\n",
    "hh_SNAP[\"snap_participation\"] = np.zeros(len(hh_SNAP))\n",
    "hh_SNAP[\"snap_participation\"] = np.where(hh_SNAP.impute==1, 2, 0)\n",
    "hh_SNAP[\"snap_participation\"] = np.where(has_val, 1, hh_SNAP.snap_participation)\n",
    "\n",
    "\n",
    "r = DataFrame(results).transpose()\n",
    "r.columns=['State', 'Imputed', 'Admin', 'adjust ratio']\n",
    "r.to_csv('amount.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_SNAP.to_csv('SNAP_Imputation.csv', \n",
    "                   columns=['snap_participation', 'snap_impute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Individual check\n",
    "imputed1 = (hh_SNAP.snap_participation == 1)\n",
    "imputed2 = (hh_SNAP.snap_participation == 2)\n",
    "\n",
    "result = {}\n",
    "\n",
    "for FIPS in admin.Fips:\n",
    "    this_state = (hh_SNAP.hh_gestfips==FIPS)\n",
    "    admin_totalindividual =  admin[\"Individual number\"][FIPS]\n",
    "    imputed_totalindividual = (hh_SNAP.hh_marsupwt* hh_SNAP.hh_size*hh_SNAP.hh_hfoodmo/12)[this_state&imputed1].sum()+(hh_SNAP.hh_marsupwt*hh_SNAP.hh_size)[this_state&imputed2].sum()\n",
    "    this_state_numindividual = [admin['State'][FIPS], admin_totalindividual, imputed_totalindividual]\n",
    "    results[FIPS] = this_state_numindividual\n",
    "    \n",
    "r = DataFrame(results).transpose()\n",
    "r.columns=['State', 'admin_totalindividual', 'imputed_totalindividual']\n",
    "r.to_csv('check_individual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Household size distribution\n",
    "result = {}\n",
    "household_weight = CPS_dataset.groupby('h_numper')['marsupwt'].sum()\n",
    "householdDistribution = DataFrame(household_weight.transpose())\n",
    "householdDistribution.columns = ['Household number']\n",
    "\n",
    "householdDistribution['Percentage'] = 100*householdDistribution['Household number']/householdDistribution['Household number'].sum()\n",
    "householdDistribution['Accumulative number'] = householdDistribution['Household number'].cumsum()\n",
    "householdDistribution['Accumulative percentage'] = 100*householdDistribution['Accumulative number']/householdDistribution['Household number'].sum()\n",
    "householdDistribution.to_csv('household_size.csv', index_label='Household size')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
